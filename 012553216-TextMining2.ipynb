{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/salihamehboob/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import load_files\n",
    "import nltk\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = load_files('/Users/salihamehboob/nltk_data/corpora/movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr .\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.data[0][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a bag of words representation of the movie review data from our previous assignment (e.g., using sklearn's CountVectorizer for bag of words representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), tokenizer=nltk.word_tokenize, analyzer='word', stop_words='english')\n",
    "X_unigram_cv = vectorizer.fit_transform(movie_reviews.data)\n",
    "print(X_unigram_cv.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#bigrams\n",
    "vectorizer2 = CountVectorizer(ngram_range=(2,2), tokenizer=nltk.word_tokenize, analyzer='word', stop_words='english')\n",
    "X_bigram_cv = vectorizer2.fit_transform(movie_reviews.data)\n",
    "print(X_bigram_cv.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tf-idf representation of the movie review data from our previous assignment (e.g., using sklearn's TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1),tokenizer=nltk.word_tokenize, analyzer='word', stop_words='english')\n",
    "X_tfidf_unigram = tfidf_vectorizer.fit_transform(movie_reviews.data)\n",
    "tfidf_vectorizer2 = TfidfVectorizer(ngram_range=(1,2),tokenizer=nltk.word_tokenize, analyzer='word', stop_words='english')\n",
    "X2_tfidf_bigram = tfidf_vectorizer2.fit_transform(movie_reviews.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_tfidf_unigram.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Bayesian classification to classify reviews into positive and negative using both the unigram and bigram versions of the bag of words and tf-idf representations from 1 and 2 above (e.g., using sklearn's MultinomialNB or nltk's NaiveBayesClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_unigram_cv, movie_reviews.target, \n",
    "                                                          test_size = 0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn\n",
    "orign_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter: {'alpha': 1, 'fit_prior': 'True'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings # supress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "param_grid = {'alpha': [0,0.5,1,10], 'fit_prior': ['True','False']}\n",
    "clf_grid = GridSearchCV(orign_model, param_grid, scoring='f1_micro')\n",
    "clf_grid.fit(X_unigram_cv,movie_reviews.target)\n",
    "print(\"best parameter:\",clf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8083333333333333\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=1,fit_prior=True)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\",sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter: {'alpha': 10, 'fit_prior': 'True'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': [0,0.5,1,10], 'fit_prior': ['True','False']}\n",
    "clf_grid = GridSearchCV(orign_model, param_grid, scoring='f1_micro')\n",
    "clf_grid.fit(X_bigram_cv,movie_reviews.target)\n",
    "print(\"best parameter:\",clf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_bigram_cv, movie_reviews.target, \n",
    "                                                          test_size = 0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Bigram: 0.7983333333333333\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=10,fit_prior=True)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy for Bigram:\",sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter for Unigram: {'alpha': 0.5, 'fit_prior': 'True'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': [0,0.5,1,10], 'fit_prior': ['True','False']}\n",
    "clf_grid = GridSearchCV(orign_model, param_grid, scoring='f1_micro')\n",
    "clf_grid.fit(X_tfidf_unigram,movie_reviews.target)\n",
    "print(\"best parameter for Unigram:\",clf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_unigram, movie_reviews.target, \n",
    "                                                          test_size = 0.3, random_state = 12)\n",
    "model = MultinomialNB(alpha=0.5,fit_prior=True)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"TFIDF Accuracy:\",sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter for Unigram: {'alpha': 0.5, 'fit_prior': 'True'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': [0,0.5,1,10], 'fit_prior': ['True','False']}\n",
    "clf_grid = GridSearchCV(orign_model, param_grid, scoring='f1_micro')\n",
    "clf_grid.fit(X2_tfidf_bigram,movie_reviews.target)\n",
    "print(\"best parameter for Biigram:\",clf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Accuracy for Bigram: 0.8033333333333333\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2_tfidf_bigram, movie_reviews.target, \n",
    "                                                          test_size = 0.3, random_state = 12)\n",
    "model = MultinomialNB(alpha=0.5,fit_prior=True)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"TFIDF Accuracy for Bigram:\",sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SVM with a linear kernel to classify reviews into positive and negative using both the unigram and bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter: {'C': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "svc_model = SVC()\n",
    "param_grid = param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "clf_grid = GridSearchCV(svc_model, param_grid, scoring='f1_micro')\n",
    "clf_grid.fit(X_unigram_cv,movie_reviews.target)\n",
    "print(\"best parameter:\",clf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy for CV: 0.8266666666666667\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_unigram_cv, movie_reviews.target, \n",
    "                                                          test_size = 0.3, random_state = 12)\n",
    "model = SVC(C=1,kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"SVC Accuracy for CV:\",sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy for CV (Bigram): 0.7533333333333333\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_bigram_cv, movie_reviews.target, \n",
    "                                                          test_size = 0.3, random_state = 12)\n",
    "model = SVC(C=1,kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"SVC Accuracy for CV (Bigram):\",sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy for CV: 0.8283333333333334\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_unigram, movie_reviews.target, \n",
    "                                                          test_size = 0.3, random_state = 12)\n",
    "model = SVC(C=1,kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"SVC Accuracy for CV:\",sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy for CV (Bigram): 0.8233333333333334\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2_tfidf_bigram, movie_reviews.target, \n",
    "                                                          test_size = 0.3, random_state = 12)\n",
    "model = SVC(C=1,kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"SVC Accuracy for CV (Bigram):\",sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
